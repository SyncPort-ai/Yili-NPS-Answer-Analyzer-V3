"""
æ•°æ®è´¨é‡å’Œå¯ä¿¡åº¦è¯„ä¼°æ¨¡å—

è¯¥æ¨¡å—å®ç°äº†å…¨é¢çš„æ•°æ®è´¨é‡è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®å®Œæ•´æ€§æ£€éªŒ
- ç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ  
- æ ·æœ¬ä»£è¡¨æ€§è¯„ä¼°
- å“åº”è´¨é‡åˆ†æ
- å¯ä¿¡åº¦è®¡ç®—

æ‰€æœ‰è¾“å‡ºéƒ½ä½¿ç”¨ä¸­æ–‡ï¼Œä½†ç±»åå’Œå˜é‡ä½¿ç”¨è‹±æ–‡ã€‚
"""

import math
import statistics
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import re
import logging

logger = logging.getLogger(__name__)

@dataclass
class DataQualityScore:
    """æ•°æ®è´¨é‡è¯„åˆ†ç»“æ„"""
    dimension: str
    score: float  # 0-100åˆ†å€¼
    status: str   # "ä¼˜ç§€", "è‰¯å¥½", "ä¸€èˆ¬", "éœ€æ”¹è¿›"
    issues: List[str]
    recommendations: List[str]

@dataclass  
class ReliabilityMetrics:
    """å¯ä¿¡åº¦æŒ‡æ ‡ç»“æ„"""
    overall_reliability: float  # æ•´ä½“å¯ä¿¡åº¦ 0-100
    data_quality_score: float   # æ•°æ®è´¨é‡åˆ†æ•°
    statistical_confidence: float  # ç»Ÿè®¡ç½®ä¿¡åº¦
    response_quality: float     # å“åº”è´¨é‡
    sample_representativeness: float  # æ ·æœ¬ä»£è¡¨æ€§
    temporal_consistency: float # æ—¶é—´ä¸€è‡´æ€§
    
class DataQualityAssessment:
    """æ•°æ®è´¨é‡è¯„ä¼°æ ¸å¿ƒç±»"""
    
    def __init__(self):
        self.quality_thresholds = {
            "excellent": 85,    # ä¼˜ç§€
            "good": 70,         # è‰¯å¥½  
            "fair": 55,         # ä¸€èˆ¬
            "poor": 40          # éœ€æ”¹è¿›
        }
        
        self.weight_config = {
            "completeness": 0.25,      # å®Œæ•´æ€§æƒé‡
            "validity": 0.20,          # æœ‰æ•ˆæ€§æƒé‡
            "consistency": 0.20,       # ä¸€è‡´æ€§æƒé‡
            "accuracy": 0.15,          # å‡†ç¡®æ€§æƒé‡
            "timeliness": 0.10,        # æ—¶æ•ˆæ€§æƒé‡
            "uniqueness": 0.10         # å”¯ä¸€æ€§æƒé‡
        }
    
    def assess_data_quality(self, data: Dict[str, Any]) -> Dict[str, DataQualityScore]:
        """
        ç»¼åˆè¯„ä¼°æ•°æ®è´¨é‡çš„å…­ä¸ªç»´åº¦
        
        Args:
            data: åŒ…å«NPSè°ƒç ”æ•°æ®çš„å­—å…¸
            
        Returns:
            å„ç»´åº¦è´¨é‡è¯„åˆ†çš„å­—å…¸
        """
        quality_scores = {}
        
        # 1. æ•°æ®å®Œæ•´æ€§è¯„ä¼°
        quality_scores['completeness'] = self._assess_completeness(data)
        
        # 2. æ•°æ®æœ‰æ•ˆæ€§è¯„ä¼°  
        quality_scores['validity'] = self._assess_validity(data)
        
        # 3. æ•°æ®ä¸€è‡´æ€§è¯„ä¼°
        quality_scores['consistency'] = self._assess_consistency(data)
        
        # 4. æ•°æ®å‡†ç¡®æ€§è¯„ä¼°
        quality_scores['accuracy'] = self._assess_accuracy(data)
        
        # 5. æ•°æ®æ—¶æ•ˆæ€§è¯„ä¼°
        quality_scores['timeliness'] = self._assess_timeliness(data)
        
        # 6. æ•°æ®å”¯ä¸€æ€§è¯„ä¼°
        quality_scores['uniqueness'] = self._assess_uniqueness(data)
        
        return quality_scores
    
    def _assess_completeness(self, data: Dict) -> DataQualityScore:
        """è¯„ä¼°æ•°æ®å®Œæ•´æ€§ - å¿…å¡«å­—æ®µå®Œæ•´ç‡"""
        issues = []
        recommendations = []
        
        required_fields = ['score', 'comment', 'customer_id', 'timestamp']
        optional_fields = ['region', 'age_group', 'product_category']
        
        if 'raw_responses' not in data:
            return DataQualityScore("å®Œæ•´æ€§", 0, "éœ€æ”¹è¿›", 
                                  ["ç¼ºå°‘åŸå§‹å“åº”æ•°æ®"], ["æä¾›å®Œæ•´çš„è°ƒç ”æ•°æ®"])
        
        responses = data['raw_responses']
        total_responses = len(responses)
        complete_responses = 0
        
        for response in responses:
            missing_required = [field for field in required_fields if field not in response or not response[field]]
            if not missing_required:
                complete_responses += 1
            else:
                issues.extend([f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}" for field in missing_required[:2]])  # é™åˆ¶æ˜¾ç¤º
        
        completeness_rate = (complete_responses / total_responses * 100) if total_responses > 0 else 0
        
        if completeness_rate < 60:
            recommendations.append("å¢åŠ æ•°æ®æ”¶é›†æµç¨‹çš„å¿…å¡«å­—æ®µéªŒè¯")
            recommendations.append("å¯¹ä¸å®Œæ•´è®°å½•è¿›è¡Œæ•°æ®æ¸…æ´—æˆ–è¡¥å……")
        
        status = self._get_quality_status(completeness_rate)
        
        return DataQualityScore("å®Œæ•´æ€§", completeness_rate, status, issues[:5], recommendations[:3])
    
    def _assess_validity(self, data: Dict) -> DataQualityScore:
        """è¯„ä¼°æ•°æ®æœ‰æ•ˆæ€§ - æ•°æ®æ ¼å¼å’ŒèŒƒå›´æ­£ç¡®æ€§"""
        issues = []
        recommendations = []
        
        if 'raw_responses' not in data:
            return DataQualityScore("æœ‰æ•ˆæ€§", 0, "éœ€æ”¹è¿›", 
                                  ["ç¼ºå°‘åŸå§‹å“åº”æ•°æ®"], ["æä¾›æœ‰æ•ˆçš„æ•°æ®æ ¼å¼"])
        
        responses = data['raw_responses']
        total_responses = len(responses)
        valid_responses = 0
        
        for response in responses:
            response_valid = True
            
            # æ£€æŸ¥NPSåˆ†æ•°èŒƒå›´ (0-10)
            if 'score' in response:
                try:
                    score = float(response['score'])
                    if not (0 <= score <= 10):
                        issues.append(f"NPSåˆ†æ•° {score} è¶…å‡ºæœ‰æ•ˆèŒƒå›´ [0-10]")
                        response_valid = False
                except (ValueError, TypeError):
                    issues.append("NPSåˆ†æ•°æ ¼å¼æ— æ•ˆ")
                    response_valid = False
            
            # æ£€æŸ¥è¯„è®ºå†…å®¹è´¨é‡
            if 'comment' in response:
                comment = str(response['comment']).strip()
                if len(comment) < 5:
                    issues.append("è¯„è®ºå†…å®¹è¿‡çŸ­")
                    response_valid = False
                elif len(comment) > 1000:
                    issues.append("è¯„è®ºå†…å®¹è¿‡é•¿")
                    response_valid = False
            
            # æ£€æŸ¥æ—¶é—´æˆ³æ ¼å¼
            if 'timestamp' in response:
                try:
                    datetime.fromisoformat(response['timestamp'].replace('Z', '+00:00'))
                except (ValueError, AttributeError):
                    issues.append("æ—¶é—´æˆ³æ ¼å¼æ— æ•ˆ")
                    response_valid = False
            
            if response_valid:
                valid_responses += 1
        
        validity_rate = (valid_responses / total_responses * 100) if total_responses > 0 else 0
        
        if validity_rate < 80:
            recommendations.append("åŠ å¼ºæ•°æ®è¾“å…¥éªŒè¯è§„åˆ™")
            recommendations.append("å¢åŠ æ•°æ®æ¸…æ´—æµç¨‹")
        
        status = self._get_quality_status(validity_rate)
        
        return DataQualityScore("æœ‰æ•ˆæ€§", validity_rate, status, issues[:5], recommendations[:3])
    
    def _assess_consistency(self, data: Dict) -> DataQualityScore:
        """è¯„ä¼°æ•°æ®ä¸€è‡´æ€§ - å†…éƒ¨é€»è¾‘å’Œæ ¼å¼ä¸€è‡´æ€§"""
        issues = []
        recommendations = []
        
        if 'raw_responses' not in data:
            return DataQualityScore("ä¸€è‡´æ€§", 0, "éœ€æ”¹è¿›", 
                                  ["ç¼ºå°‘åŸå§‹å“åº”æ•°æ®"], ["ç¡®ä¿æ•°æ®æ ¼å¼ä¸€è‡´"])
        
        responses = data['raw_responses']
        consistency_score = 100
        
        # æ£€æŸ¥è¯„è®ºä¸åˆ†æ•°çš„ä¸€è‡´æ€§
        inconsistent_count = 0
        positive_words = ['å–œæ¬¢', 'å¥½', 'æ£’', 'ä¼˜ç§€', 'æ¨è', 'æ»¡æ„']
        negative_words = ['ä¸å¥½', 'å·®', 'å¤±æœ›', 'é—®é¢˜', 'ç³Ÿç³•', 'ä¸æ»¡']
        
        for response in responses:
            if 'score' in response and 'comment' in response:
                try:
                    score = float(response['score'])
                    comment = str(response['comment']).lower()
                    
                    # é«˜åˆ†ä½†è´Ÿé¢è¯„è®º
                    if score >= 7 and any(word in comment for word in negative_words):
                        inconsistent_count += 1
                        issues.append(f"é«˜åˆ†({score})ä½†è¯„è®ºåè´Ÿé¢")
                    
                    # ä½åˆ†ä½†æ­£é¢è¯„è®º
                    elif score <= 4 and any(word in comment for word in positive_words):
                        inconsistent_count += 1
                        issues.append(f"ä½åˆ†({score})ä½†è¯„è®ºåæ­£é¢")
                    
                except (ValueError, TypeError):
                    continue
        
        if inconsistent_count > 0:
            inconsistency_rate = (inconsistent_count / len(responses)) * 100
            consistency_score = max(0, 100 - inconsistency_rate * 2)  # æ¯ä¸ªä¸ä¸€è‡´é¡¹æ‰£2åˆ†
            
            if inconsistency_rate > 20:
                recommendations.append("å®¡æŸ¥è¯„åˆ†ä¸è¯„è®ºçš„åŒ¹é…æ€§")
                recommendations.append("å¢åŠ æ•°æ®è´¨é‡åŸ¹è®­")
        
        status = self._get_quality_status(consistency_score)
        
        return DataQualityScore("ä¸€è‡´æ€§", consistency_score, status, issues[:5], recommendations[:3])
    
    def _assess_accuracy(self, data: Dict) -> DataQualityScore:
        """è¯„ä¼°æ•°æ®å‡†ç¡®æ€§ - ä¿¡æ¯çœŸå®æ€§å’Œå¯éªŒè¯æ€§"""
        issues = []
        recommendations = []
        
        if 'raw_responses' not in data:
            return DataQualityScore("å‡†ç¡®æ€§", 0, "éœ€æ”¹è¿›", 
                                  ["ç¼ºå°‘åŸå§‹å“åº”æ•°æ®"], ["éªŒè¯æ•°æ®æ¥æºå‡†ç¡®æ€§"])
        
        responses = data['raw_responses']
        accuracy_score = 100
        accuracy_issues = 0
        
        # æ£€æŸ¥å¼‚å¸¸æ¨¡å¼
        for response in responses:
            if 'comment' in response:
                comment = str(response['comment'])
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«PIIä¿¡æ¯ï¼ˆéšç§æ³„éœ²é£é™©ï¼‰
                if re.search(r'(\d{11}|\d{3}-\d{4}-\d{4})', comment):  # æ‰‹æœºå·æ¨¡å¼
                    accuracy_issues += 1
                    issues.append("è¯„è®ºä¸­åŒ…å«æ•æ„Ÿä¸ªäººä¿¡æ¯")
                
                if re.search(r'\w+@\w+\.\w+', comment):  # é‚®ç®±æ¨¡å¼
                    accuracy_issues += 1
                    issues.append("è¯„è®ºä¸­åŒ…å«é‚®ç®±åœ°å€")
                
                # æ£€æŸ¥æ˜æ˜¾è™šå‡æˆ–æµ‹è¯•å†…å®¹
                test_patterns = ['æµ‹è¯•', 'test', 'å‡çš„', 'éšä¾¿å†™']
                if any(pattern in comment.lower() for pattern in test_patterns):
                    accuracy_issues += 1
                    issues.append("å‘ç°ç–‘ä¼¼æµ‹è¯•æˆ–è™šå‡å†…å®¹")
        
        # è®¡ç®—å‡†ç¡®æ€§åˆ†æ•°
        if accuracy_issues > 0:
            accuracy_rate = (accuracy_issues / len(responses)) * 100
            accuracy_score = max(0, 100 - accuracy_rate * 5)  # æ¯ä¸ªé—®é¢˜æ‰£5åˆ†
            
            if accuracy_rate > 10:
                recommendations.append("åŠ å¼ºæ•°æ®æ¥æºéªŒè¯")
                recommendations.append("å®æ–½PIIè‡ªåŠ¨æ£€æµ‹å’Œæ¸…æ´—")
                recommendations.append("å»ºç«‹æ•°æ®çœŸå®æ€§å®¡æ ¸æœºåˆ¶")
        
        status = self._get_quality_status(accuracy_score)
        
        return DataQualityScore("å‡†ç¡®æ€§", accuracy_score, status, issues[:5], recommendations[:3])
    
    def _assess_timeliness(self, data: Dict) -> DataQualityScore:
        """è¯„ä¼°æ•°æ®æ—¶æ•ˆæ€§ - æ•°æ®æ”¶é›†çš„æ—¶é—´è·¨åº¦å’Œæ–°é²œåº¦"""
        issues = []
        recommendations = []
        
        if 'raw_responses' not in data:
            return DataQualityScore("æ—¶æ•ˆæ€§", 0, "éœ€æ”¹è¿›", 
                                  ["ç¼ºå°‘åŸå§‹å“åº”æ•°æ®"], ["ç¡®ä¿æ•°æ®æ—¶æ•ˆæ€§"])
        
        responses = data['raw_responses']
        current_time = datetime.now()
        valid_timestamps = []
        
        for response in responses:
            if 'timestamp' in response:
                try:
                    ts = datetime.fromisoformat(response['timestamp'].replace('Z', '+00:00'))
                    valid_timestamps.append(ts.replace(tzinfo=None))
                except (ValueError, AttributeError):
                    continue
        
        if not valid_timestamps:
            return DataQualityScore("æ—¶æ•ˆæ€§", 0, "éœ€æ”¹è¿›", 
                                  ["æ— æœ‰æ•ˆæ—¶é—´æˆ³"], ["æ·»åŠ æœ‰æ•ˆçš„æ—¶é—´æˆ³ä¿¡æ¯"])
        
        # è®¡ç®—æ—¶é—´è·¨åº¦å’Œæ–°é²œåº¦
        oldest_time = min(valid_timestamps)
        newest_time = max(valid_timestamps)
        time_span = (newest_time - oldest_time).days
        data_age = (current_time - newest_time).days
        
        timeliness_score = 100
        
        # è¯„ä¼°æ•°æ®æ–°é²œåº¦
        if data_age > 365:  # è¶…è¿‡1å¹´
            timeliness_score -= 30
            issues.append(f"æ•°æ®è¿‡äºé™ˆæ—§ ({data_age}å¤©å‰)")
        elif data_age > 180:  # è¶…è¿‡6ä¸ªæœˆ
            timeliness_score -= 15
            issues.append(f"æ•°æ®è¾ƒä¸ºé™ˆæ—§ ({data_age}å¤©å‰)")
        elif data_age > 90:   # è¶…è¿‡3ä¸ªæœˆ
            timeliness_score -= 5
            issues.append(f"æ•°æ®ç¨æ˜¾é™ˆæ—§ ({data_age}å¤©å‰)")
        
        # è¯„ä¼°æ—¶é—´è·¨åº¦åˆç†æ€§
        if time_span < 1:
            timeliness_score -= 10
            issues.append("æ•°æ®æ”¶é›†æ—¶é—´è¿‡äºé›†ä¸­")
            recommendations.append("å¢åŠ æ•°æ®æ”¶é›†çš„æ—¶é—´è·¨åº¦")
        elif time_span > 365:
            timeliness_score -= 20
            issues.append(f"æ•°æ®æ—¶é—´è·¨åº¦è¿‡å¤§ ({time_span}å¤©)")
            recommendations.append("ç¼©çŸ­æ•°æ®åˆ†æçš„æ—¶é—´çª—å£")
        
        if timeliness_score < 70:
            recommendations.append("å»ºç«‹å®šæœŸæ•°æ®æ›´æ–°æœºåˆ¶")
            recommendations.append("è®¾ç½®æ•°æ®æœ‰æ•ˆæœŸç®¡ç†")
        
        status = self._get_quality_status(timeliness_score)
        
        return DataQualityScore("æ—¶æ•ˆæ€§", timeliness_score, status, issues[:5], recommendations[:3])
    
    def _assess_uniqueness(self, data: Dict) -> DataQualityScore:
        """è¯„ä¼°æ•°æ®å”¯ä¸€æ€§ - é‡å¤è®°å½•æ£€æµ‹"""
        issues = []
        recommendations = []
        
        if 'raw_responses' not in data:
            return DataQualityScore("å”¯ä¸€æ€§", 0, "éœ€æ”¹è¿›", 
                                  ["ç¼ºå°‘åŸå§‹å“åº”æ•°æ®"], ["ç¡®ä¿æ•°æ®å”¯ä¸€æ€§"])
        
        responses = data['raw_responses']
        total_responses = len(responses)
        
        # æ£€æŸ¥customer_idé‡å¤
        customer_ids = [r.get('customer_id') for r in responses if r.get('customer_id')]
        unique_customers = len(set(customer_ids))
        customer_duplication_rate = ((len(customer_ids) - unique_customers) / len(customer_ids) * 100) if customer_ids else 0
        
        # æ£€æŸ¥è¯„è®ºå†…å®¹é‡å¤
        comments = [r.get('comment', '').strip() for r in responses if r.get('comment')]
        unique_comments = len(set(comments))
        comment_duplication_rate = ((len(comments) - unique_comments) / len(comments) * 100) if comments else 0
        
        uniqueness_score = 100
        
        if customer_duplication_rate > 5:
            uniqueness_score -= customer_duplication_rate
            issues.append(f"å®¢æˆ·IDé‡å¤ç‡: {customer_duplication_rate:.1f}%")
            recommendations.append("æ£€æŸ¥å®¢æˆ·IDåˆ†é…æœºåˆ¶")
        
        if comment_duplication_rate > 10:
            uniqueness_score -= comment_duplication_rate / 2
            issues.append(f"è¯„è®ºå†…å®¹é‡å¤ç‡: {comment_duplication_rate:.1f}%")
            recommendations.append("å¢åŠ è¯„è®ºå†…å®¹å¤šæ ·æ€§éªŒè¯")
        
        # æ£€æŸ¥å®Œå…¨ç›¸åŒçš„è®°å½•
        response_strings = [str(sorted(r.items())) for r in responses]
        unique_responses = len(set(response_strings))
        exact_duplication_rate = ((total_responses - unique_responses) / total_responses * 100) if total_responses > 0 else 0
        
        if exact_duplication_rate > 0:
            uniqueness_score -= exact_duplication_rate * 2
            issues.append(f"å®Œå…¨é‡å¤è®°å½•ç‡: {exact_duplication_rate:.1f}%")
            recommendations.append("å®æ–½é‡å¤è®°å½•è‡ªåŠ¨æ£€æµ‹å’Œæ¸…é™¤")
        
        status = self._get_quality_status(uniqueness_score)
        
        return DataQualityScore("å”¯ä¸€æ€§", uniqueness_score, status, issues[:5], recommendations[:3])
    
    def calculate_reliability_metrics(self, data: Dict[str, Any], 
                                    quality_scores: Dict[str, DataQualityScore]) -> ReliabilityMetrics:
        """
        è®¡ç®—ç»¼åˆå¯ä¿¡åº¦æŒ‡æ ‡
        
        Args:
            data: åŸå§‹æ•°æ®
            quality_scores: æ•°æ®è´¨é‡è¯„åˆ†
            
        Returns:
            å¯ä¿¡åº¦æŒ‡æ ‡å¯¹è±¡
        """
        # è®¡ç®—åŠ æƒæ•°æ®è´¨é‡åˆ†æ•°
        data_quality_score = sum(
            quality_scores[dimension].score * self.weight_config[dimension]
            for dimension in quality_scores.keys()
            if dimension in self.weight_config
        )
        
        # è®¡ç®—ç»Ÿè®¡ç½®ä¿¡åº¦
        statistical_confidence = self._calculate_statistical_confidence(data)
        
        # è®¡ç®—å“åº”è´¨é‡
        response_quality = self._calculate_response_quality(data)
        
        # è®¡ç®—æ ·æœ¬ä»£è¡¨æ€§
        sample_representativeness = self._calculate_sample_representativeness(data)
        
        # è®¡ç®—æ—¶é—´ä¸€è‡´æ€§
        temporal_consistency = self._calculate_temporal_consistency(data)
        
        # è®¡ç®—æ•´ä½“å¯ä¿¡åº¦ (ç»¼åˆæƒé‡)
        reliability_weights = {
            'data_quality': 0.35,
            'statistical_confidence': 0.25,
            'response_quality': 0.20,
            'sample_representativeness': 0.15,
            'temporal_consistency': 0.05
        }
        
        overall_reliability = (
            data_quality_score * reliability_weights['data_quality'] +
            statistical_confidence * reliability_weights['statistical_confidence'] +
            response_quality * reliability_weights['response_quality'] +
            sample_representativeness * reliability_weights['sample_representativeness'] +
            temporal_consistency * reliability_weights['temporal_consistency']
        )
        
        return ReliabilityMetrics(
            overall_reliability=round(overall_reliability, 2),
            data_quality_score=round(data_quality_score, 2),
            statistical_confidence=round(statistical_confidence, 2),
            response_quality=round(response_quality, 2),
            sample_representativeness=round(sample_representativeness, 2),
            temporal_consistency=round(temporal_consistency, 2)
        )
    
    def _calculate_statistical_confidence(self, data: Dict) -> float:
        """è®¡ç®—ç»Ÿè®¡ç½®ä¿¡åº¦"""
        if 'raw_responses' not in data:
            return 0.0
        
        responses = data['raw_responses']
        sample_size = len(responses)
        
        # åŸºäºæ ·æœ¬é‡çš„ç½®ä¿¡åº¦è®¡ç®—
        if sample_size >= 400:
            base_confidence = 95
        elif sample_size >= 100:
            base_confidence = 85
        elif sample_size >= 30:
            base_confidence = 75
        elif sample_size >= 10:
            base_confidence = 60
        else:
            base_confidence = 40
        
        # è€ƒè™‘åˆ†æ•°åˆ†å¸ƒçš„æ–¹å·®
        scores = [float(r.get('score', 5)) for r in responses if 'score' in r]
        if len(scores) > 1:
            score_std = statistics.stdev(scores)
            # æ ‡å‡†å·®è¶Šå¤§ï¼Œç½®ä¿¡åº¦è¶Šä½
            variance_penalty = min(score_std * 5, 20)  # æœ€å¤šæ‰£20åˆ†
            base_confidence -= variance_penalty
        
        return max(0, min(100, base_confidence))
    
    def _calculate_response_quality(self, data: Dict) -> float:
        """è®¡ç®—å“åº”è´¨é‡åˆ†æ•°"""
        if 'raw_responses' not in data:
            return 0.0
        
        responses = data['raw_responses']
        total_responses = len(responses)
        quality_score = 100
        
        # è¯„ä¼°è¯„è®ºè´¨é‡
        low_quality_count = 0
        for response in responses:
            comment = str(response.get('comment', '')).strip()
            
            # è¯„è®ºé•¿åº¦è¯„ä¼°
            if len(comment) < 10:
                low_quality_count += 1
            elif len(comment) > 200:
                # é•¿è¯„è®ºé€šå¸¸è´¨é‡æ›´é«˜
                continue
            
            # è¯„ä¼°è¯„è®ºä¿¡æ¯é‡
            words = comment.split()
            if len(words) < 3:
                low_quality_count += 1
        
        if total_responses > 0:
            low_quality_rate = (low_quality_count / total_responses) * 100
            quality_score = max(0, 100 - low_quality_rate)
        
        return quality_score
    
    def _calculate_sample_representativeness(self, data: Dict) -> float:
        """è®¡ç®—æ ·æœ¬ä»£è¡¨æ€§åˆ†æ•°"""
        if 'raw_responses' not in data:
            return 0.0
        
        responses = data['raw_responses']
        representativeness_score = 100
        
        # æ£€æŸ¥åœ°åŸŸåˆ†å¸ƒ
        regions = [r.get('region') for r in responses if r.get('region')]
        unique_regions = len(set(regions))
        if unique_regions < 3 and len(regions) > 5:
            representativeness_score -= 15
        
        # æ£€æŸ¥å¹´é¾„åˆ†å¸ƒ
        age_groups = [r.get('age_group') for r in responses if r.get('age_group')]
        unique_age_groups = len(set(age_groups))
        if unique_age_groups < 3 and len(age_groups) > 5:
            representativeness_score -= 15
        
        # æ£€æŸ¥åˆ†æ•°åˆ†å¸ƒ
        scores = [float(r.get('score', 5)) for r in responses if 'score' in r]
        if scores:
            score_range = max(scores) - min(scores)
            if score_range < 3:  # åˆ†æ•°è¿‡äºé›†ä¸­
                representativeness_score -= 20
        
        return max(0, representativeness_score)
    
    def _calculate_temporal_consistency(self, data: Dict) -> float:
        """è®¡ç®—æ—¶é—´ä¸€è‡´æ€§åˆ†æ•°"""
        if 'raw_responses' not in data:
            return 0.0
        
        responses = data['raw_responses']
        timestamps = []
        
        for response in responses:
            if 'timestamp' in response:
                try:
                    ts = datetime.fromisoformat(response['timestamp'].replace('Z', '+00:00'))
                    timestamps.append(ts)
                except (ValueError, AttributeError):
                    continue
        
        if len(timestamps) < 2:
            return 50  # æ— æ³•åˆ¤æ–­ï¼Œç»™ä¸­ç­‰åˆ†
        
        # è®¡ç®—æ—¶é—´åˆ†å¸ƒçš„å‡åŒ€æ€§
        timestamps.sort()
        time_intervals = [(timestamps[i+1] - timestamps[i]).total_seconds() 
                         for i in range(len(timestamps)-1)]
        
        if time_intervals:
            avg_interval = statistics.mean(time_intervals)
            if avg_interval < 60:  # é—´éš”è¿‡çŸ­å¯èƒ½æ˜¯æ‰¹é‡ç”Ÿæˆ
                return 60
            elif avg_interval > 86400 * 30:  # é—´éš”è¿‡é•¿å¯èƒ½ç¼ºä¹è¿ç»­æ€§
                return 70
            else:
                return 90
        
        return 75
    
    def _get_quality_status(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è·å–è´¨é‡çŠ¶æ€"""
        if score >= self.quality_thresholds["excellent"]:
            return "ä¼˜ç§€"
        elif score >= self.quality_thresholds["good"]:
            return "è‰¯å¥½"
        elif score >= self.quality_thresholds["fair"]:
            return "ä¸€èˆ¬"
        else:
            return "éœ€æ”¹è¿›"
    
    def generate_quality_summary(self, quality_scores: Dict[str, DataQualityScore], 
                                reliability_metrics: ReliabilityMetrics) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ•°æ®è´¨é‡å’Œå¯ä¿¡åº¦æ€»ç»“æŠ¥å‘Š
        
        Args:
            quality_scores: è´¨é‡è¯„åˆ†å­—å…¸
            reliability_metrics: å¯ä¿¡åº¦æŒ‡æ ‡
            
        Returns:
            è´¨é‡æ€»ç»“æŠ¥å‘Š
        """
        # è¯†åˆ«ä¸»è¦é—®é¢˜é¢†åŸŸ
        problem_areas = [
            dimension for dimension, score in quality_scores.items()
            if score.score < self.quality_thresholds["good"]
        ]
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        all_recommendations = []
        for score in quality_scores.values():
            all_recommendations.extend(score.recommendations)
        
        # å»é‡å¹¶ä¼˜å…ˆæ’åº
        unique_recommendations = list(dict.fromkeys(all_recommendations))[:5]
        
        # ç¡®å®šæ•´ä½“è´¨é‡ç­‰çº§
        overall_score = reliability_metrics.overall_reliability
        overall_status = self._get_quality_status(overall_score)
        
        return {
            "æ•´ä½“è´¨é‡ç­‰çº§": overall_status,
            "æ•´ä½“å¯ä¿¡åº¦åˆ†æ•°": overall_score,
            "è´¨é‡ç»´åº¦è¯„åˆ†": {
                dimension: {
                    "åˆ†æ•°": score.score,
                    "çŠ¶æ€": score.status,
                    "ä¸»è¦é—®é¢˜æ•°": len(score.issues)
                }
                for dimension, score in quality_scores.items()
            },
            "å¯ä¿¡åº¦ç»†åˆ†æŒ‡æ ‡": {
                "æ•°æ®è´¨é‡åˆ†æ•°": reliability_metrics.data_quality_score,
                "ç»Ÿè®¡ç½®ä¿¡åº¦": reliability_metrics.statistical_confidence,
                "å“åº”è´¨é‡": reliability_metrics.response_quality,
                "æ ·æœ¬ä»£è¡¨æ€§": reliability_metrics.sample_representativeness,
                "æ—¶é—´ä¸€è‡´æ€§": reliability_metrics.temporal_consistency
            },
            "é‡ç‚¹å…³æ³¨é¢†åŸŸ": problem_areas,
            "æ”¹è¿›å»ºè®®": unique_recommendations,
            "è´¨é‡é£é™©æç¤º": self._generate_risk_alerts(quality_scores, reliability_metrics)
        }
    
    def _generate_risk_alerts(self, quality_scores: Dict[str, DataQualityScore], 
                             reliability_metrics: ReliabilityMetrics) -> List[str]:
        """ç”Ÿæˆè´¨é‡é£é™©æç¤º"""
        alerts = []
        
        if reliability_metrics.overall_reliability < 50:
            alerts.append("ğŸ”´ æ•´ä½“æ•°æ®å¯ä¿¡åº¦ä½ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨åˆ†æç»“æœ")
        
        if reliability_metrics.statistical_confidence < 60:
            alerts.append("ğŸŸ¡ ç»Ÿè®¡ç½®ä¿¡åº¦ä¸è¶³ï¼Œç»“è®ºå¯èƒ½å­˜åœ¨è¾ƒå¤§è¯¯å·®")
        
        if quality_scores.get('accuracy', DataQualityScore("", 100, "", [], [])).score < 70:
            alerts.append("ğŸŸ¡ æ•°æ®å‡†ç¡®æ€§å­˜ç–‘ï¼Œå»ºè®®è¿›è¡Œäººå·¥å®¡æ ¸")
        
        if quality_scores.get('completeness', DataQualityScore("", 100, "", [], [])).score < 60:
            alerts.append("ğŸŸ¡ æ•°æ®å®Œæ•´æ€§ä¸è¶³ï¼Œå¯èƒ½å½±å“åˆ†æå…¨é¢æ€§")
        
        if reliability_metrics.sample_representativeness < 70:
            alerts.append("ğŸŸ¡ æ ·æœ¬ä»£è¡¨æ€§æœ‰é™ï¼Œç»“è®ºæ¨å¹¿æ€§å¯èƒ½å—é™")
        
        return alerts