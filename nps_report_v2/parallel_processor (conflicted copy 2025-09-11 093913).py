"""
V1/V2å¹¶è¡Œå¤„ç†ç®¡ç†å™¨
è´Ÿè´£åè°ƒV1å’ŒV2çš„å¹¶è¡Œæ‰§è¡Œï¼Œå¤„ç†ç»“æœåˆå¹¶å’Œé™çº§ç­–ç•¥
"""

import asyncio
import json
import logging
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from datetime import datetime
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

from .input_data_processor import InputDataProcessor, ProcessedSurveyData
from .nps_data_processor import NPSDataProcessor, ProcessedNPSData
from .data_recorder import DataRecorder

# å¯¼å…¥V2æœ¬åœ°å‰¯æœ¬çš„V1å¤„ç†é€»è¾‘ï¼Œé¿å…ä¸åŸå§‹V1æ–‡ä»¶å†²çª
from .v1_legacy_analysis import v1_legacy_auto_analysis

# é…ç½®è¯¦ç»†æ—¥å¿—
try:
    from .utils.logging_config import get_logger, log_function_call
    logger = get_logger(__name__)
except ImportError:
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    # å¦‚æœæ²¡æœ‰è¯¦ç»†æ—¥å¿—ç³»ç»Ÿï¼Œåˆ›å»ºä¸€ä¸ªç©ºè£…é¥°å™¨
    def log_function_call():
        def decorator(func):
            return func
        return decorator

@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœæ•°æ®ç»“æ„"""
    version: str  # "v1" or "v2"
    success: bool
    result: Optional[Dict[str, Any]]
    error: Optional[str]
    processing_time: float
    timestamp: str

@dataclass
class ParallelProcessingResult:
    """å¹¶è¡Œå¤„ç†ç»“æœ"""
    request_id: str
    input_data: Dict[str, Any]
    v1_result: ProcessingResult
    v2_result: ProcessingResult
    merged_result: Dict[str, Any]
    comparison_analysis: Dict[str, Any]
    final_status: str  # "success", "v1_fallback", "failure"
    total_processing_time: float

class ParallelProcessor:
    """V1/V2å¹¶è¡Œå¤„ç†å™¨"""
    
    def __init__(self, enable_v2: bool = True, v2_timeout: float = 300.0):
        """
        åˆå§‹åŒ–å¹¶è¡Œå¤„ç†å™¨
        
        Args:
            enable_v2: æ˜¯å¦å¯ç”¨V2å¤„ç†
            v2_timeout: V2å¤„ç†è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.enable_v2 = enable_v2
        self.v2_timeout = v2_timeout
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.input_processor = InputDataProcessor()
        self.nps_processor = NPSDataProcessor()
        self.data_recorder = DataRecorder()
        
        # çº¿ç¨‹æ± 
        self.executor = ThreadPoolExecutor(max_workers=2)
        
        logger.info(f"å¹¶è¡Œå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ - V2å¯ç”¨: {enable_v2}, è¶…æ—¶: {v2_timeout}s")
    
    @log_function_call()
    async def process_parallel(self, raw_input_data: Dict[str, Any], 
                             request_id: Optional[str] = None) -> ParallelProcessingResult:
        """
        å¹¶è¡Œå¤„ç†ä¸»å…¥å£å‡½æ•°
        
        Args:
            raw_input_data: åŸå§‹è¾“å…¥æ•°æ®
            request_id: è¯·æ±‚IDï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ParallelProcessingResult: å¹¶è¡Œå¤„ç†ç»“æœ
        """
        start_time = time.time()
        
        if not request_id:
            request_id = f"req_{int(time.time() * 1000)}"
        
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç† - è¯·æ±‚ID: {request_id}")
        logger.debug(f"ğŸ“¥ åŸå§‹è¾“å…¥æ•°æ®é”®å€¼: {list(raw_input_data.keys())}")
        logger.debug(f"âš™ï¸ V2å¯ç”¨çŠ¶æ€: {self.enable_v2}, è¶…æ—¶è®¾ç½®: {self.v2_timeout}s")
        
        try:
            # è®°å½•è¾“å…¥æ•°æ®
            await self.data_recorder.record_input(request_id, raw_input_data)
            
            # åˆ›å»ºå¤„ç†ä»»åŠ¡
            tasks = []
            
            # V1å¤„ç†ä»»åŠ¡
            v1_task = asyncio.create_task(
                self._process_v1(raw_input_data, request_id)
            )
            tasks.append(("v1", v1_task))
            
            # V2å¤„ç†ä»»åŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.enable_v2:
                v2_task = asyncio.create_task(
                    self._process_v2(raw_input_data, request_id)
                )
                tasks.append(("v2", v2_task))
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
            v1_result = None
            v2_result = None
            
            for version, task in tasks:
                try:
                    if version == "v2":
                        result = await asyncio.wait_for(task, timeout=self.v2_timeout)
                    else:
                        result = await task
                    
                    if version == "v1":
                        v1_result = result
                    else:
                        v2_result = result
                        
                except asyncio.TimeoutError:
                    logger.warning(f"{version.upper()}å¤„ç†è¶…æ—¶")
                    if version == "v1":
                        v1_result = ProcessingResult(
                            version="v1",
                            success=False,
                            result=None,
                            error="å¤„ç†è¶…æ—¶",
                            processing_time=self.v2_timeout,
                            timestamp=datetime.now().isoformat()
                        )
                    else:
                        v2_result = ProcessingResult(
                            version="v2",
                            success=False,
                            result=None,
                            error="å¤„ç†è¶…æ—¶",
                            processing_time=self.v2_timeout,
                            timestamp=datetime.now().isoformat()
                        )
                except Exception as e:
                    logger.error(f"{version.upper()}å¤„ç†å‡ºé”™: {e}")
                    if version == "v1":
                        v1_result = ProcessingResult(
                            version="v1",
                            success=False,
                            result=None,
                            error=str(e),
                            processing_time=time.time() - start_time,
                            timestamp=datetime.now().isoformat()
                        )
                    else:
                        v2_result = ProcessingResult(
                            version="v2",
                            success=False,
                            result=None,
                            error=str(e),
                            processing_time=time.time() - start_time,
                            timestamp=datetime.now().isoformat()
                        )
            
            # å¦‚æœV2æœªå¯ç”¨ï¼Œåˆ›å»ºé»˜è®¤V2ç»“æœ
            if not self.enable_v2:
                v2_result = ProcessingResult(
                    version="v2",
                    success=False,
                    result=None,
                    error="V2å¤„ç†æœªå¯ç”¨",
                    processing_time=0,
                    timestamp=datetime.now().isoformat()
                )
            
            # åˆå¹¶ç»“æœå’Œå†³å®šæœ€ç»ˆçŠ¶æ€
            merged_result, final_status = self._merge_results(v1_result, v2_result)
            
            # ç”Ÿæˆå¯¹æ¯”åˆ†æ
            comparison_analysis = self._generate_comparison_analysis(v1_result, v2_result)
            
            # åˆ›å»ºæœ€ç»ˆç»“æœ
            parallel_result = ParallelProcessingResult(
                request_id=request_id,
                input_data=raw_input_data,
                v1_result=v1_result,
                v2_result=v2_result,
                merged_result=merged_result,
                comparison_analysis=comparison_analysis,
                final_status=final_status,
                total_processing_time=time.time() - start_time
            )
            
            # è®°å½•å¤„ç†ç»“æœ
            await self.data_recorder.record_processing_result(request_id, parallel_result)
            
            logger.info(f"å¹¶è¡Œå¤„ç†å®Œæˆ - è¯·æ±‚ID: {request_id}, çŠ¶æ€: {final_status}, è€—æ—¶: {parallel_result.total_processing_time:.2f}s")
            
            return parallel_result
            
        except Exception as e:
            logger.error(f"å¹¶è¡Œå¤„ç†å¤±è´¥ - è¯·æ±‚ID: {request_id}, é”™è¯¯: {e}")
            logger.error(traceback.format_exc())
            
            # åˆ›å»ºå¤±è´¥ç»“æœ
            return ParallelProcessingResult(
                request_id=request_id,
                input_data=raw_input_data,
                v1_result=ProcessingResult("v1", False, None, str(e), 0, datetime.now().isoformat()),
                v2_result=ProcessingResult("v2", False, None, str(e), 0, datetime.now().isoformat()),
                merged_result={"error": str(e)},
                comparison_analysis={"error": "å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå¯¹æ¯”åˆ†æ"},
                final_status="failure",
                total_processing_time=time.time() - start_time
            )
    
    async def _process_v1(self, input_data: Dict[str, Any], request_id: str) -> ProcessingResult:
        """æ‰§è¡ŒV1å¤„ç†é€»è¾‘"""
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹V1å¤„ç† - è¯·æ±‚ID: {request_id}")
            
            # è°ƒç”¨V1çš„auto_analysiså‡½æ•°
            # éœ€è¦å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸ºV1æœŸæœ›çš„æ ¼å¼
            v1_input = self._convert_to_v1_format(input_data)
            
            # è°ƒç”¨V2æœ¬åœ°å‰¯æœ¬çš„V1ç®—æ³•ï¼ˆå·²ç»æ˜¯å¼‚æ­¥çš„ï¼‰
            v1_result = await v1_legacy_auto_analysis(v1_input)
            
            processing_time = time.time() - start_time
            
            result = ProcessingResult(
                version="v1",
                success=True,
                result=v1_result,
                error=None,
                processing_time=processing_time,
                timestamp=datetime.now().isoformat()
            )
            
            logger.info(f"V1å¤„ç†å®Œæˆ - è¯·æ±‚ID: {request_id}, è€—æ—¶: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"V1å¤„ç†å¤±è´¥ - è¯·æ±‚ID: {request_id}, é”™è¯¯: {e}")
            
            return ProcessingResult(
                version="v1",
                success=False,
                result=None,
                error=str(e),
                processing_time=processing_time,
                timestamp=datetime.now().isoformat()
            )
    
    async def _process_v2(self, input_data: Dict[str, Any], request_id: str) -> ProcessingResult:
        """æ‰§è¡ŒV2å¤„ç†é€»è¾‘"""
        start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹V2å¤„ç† - è¯·æ±‚ID: {request_id}")
            
            # V2å¤„ç†æµç¨‹
            # 1. è¾“å…¥æ•°æ®å¤„ç†
            processed_survey = self.input_processor.process_survey_data(input_data)
            
            # 2. NPSæ•°æ®å¤„ç†
            processed_nps = self.nps_processor.process_nps_data(processed_survey)
            
            # 3. è½¬æ¢ä¸ºè¿”å›æ ¼å¼
            v2_result = {
                "survey_analysis": asdict(processed_survey),
                "nps_analysis": asdict(processed_nps),
                "enhancement_type": "v2_multi_agent",
                "processing_metadata": {
                    "version": "2.0",
                    "agents_used": ["input_processor", "nps_processor"],
                    "processing_stages": 2
                }
            }
            
            processing_time = time.time() - start_time
            
            result = ProcessingResult(
                version="v2",
                success=True,
                result=v2_result,
                error=None,
                processing_time=processing_time,
                timestamp=datetime.now().isoformat()
            )
            
            logger.info(f"V2å¤„ç†å®Œæˆ - è¯·æ±‚ID: {request_id}, è€—æ—¶: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"V2å¤„ç†å¤±è´¥ - è¯·æ±‚ID: {request_id}, é”™è¯¯: {e}")
            
            return ProcessingResult(
                version="v2",
                success=False,
                result=None,
                error=str(e),
                processing_time=processing_time,
                timestamp=datetime.now().isoformat()
            )
    
    def _convert_to_v1_format(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸ºV1æœŸæœ›çš„æ ¼å¼"""
        try:
            # å¦‚æœè¾“å…¥å·²ç»æ˜¯V1æ ¼å¼ï¼Œç›´æ¥è¿”å›
            if 'wordInfos' in input_data:
                return input_data
            
            # å¦‚æœæ˜¯V2æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
            if 'survey_response_data' in input_data:
                survey_data = input_data['survey_response_data']
                responses = survey_data.get('response_data', [])
                
                # æå–æ–‡æœ¬ä¿¡æ¯åˆ›å»ºwordInfos
                word_infos = []
                word_id = 1
                
                for response in responses:
                    # æå–å¼€æ”¾æ€§å›ç­”
                    open_responses = response.get('open_responses', {})
                    if 'specific_reasons' in open_responses:
                        reasons = open_responses['specific_reasons']
                        for key, text in reasons.items():
                            if text and text.strip():
                                word_infos.append({
                                    'ids': [word_id],
                                    'word': text.strip()
                                })
                                word_id += 1
                
                # åˆ›å»ºV1æ ¼å¼çš„æ•°æ®
                v1_data = {
                    'emotionalType': 1,  # é»˜è®¤æƒ…æ„Ÿç±»å‹
                    'taskType': 1,       # é»˜è®¤ä»»åŠ¡ç±»å‹
                    'questionId': 'nps_survey',
                    'wordInfos': word_infos
                }
                
                return v1_data
            
            # å¦‚æœæ ¼å¼ä¸æ˜ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
            return input_data
            
        except Exception as e:
            logger.warning(f"æ•°æ®æ ¼å¼è½¬æ¢å¤±è´¥: {e}, ä½¿ç”¨åŸå§‹æ•°æ®")
            return input_data
    
    def _merge_results(self, v1_result: ProcessingResult, v2_result: ProcessingResult) -> Tuple[Dict[str, Any], str]:
        """åˆå¹¶V1å’ŒV2çš„å¤„ç†ç»“æœ"""
        
        # å†³å®šæœ€ç»ˆçŠ¶æ€å’Œä½¿ç”¨å“ªä¸ªç»“æœ
        if v1_result.success and v2_result.success:
            # ä¸¤ä¸ªéƒ½æˆåŠŸï¼Œåˆå¹¶ç»“æœ
            merged_result = {
                "status": "success",
                "v1_analysis": v1_result.result,
                "v2_enhancement": v2_result.result,
                "primary_result": v2_result.result,  # V2ä¸ºä¸»è¦ç»“æœ
                "fallback_result": v1_result.result,  # V1ä¸ºå¤‡ç”¨ç»“æœ
                "processing_info": {
                    "v1_processing_time": v1_result.processing_time,
                    "v2_processing_time": v2_result.processing_time,
                    "enhancement_applied": True
                }
            }
            final_status = "success"
            
        elif v1_result.success and not v2_result.success:
            # V1æˆåŠŸï¼ŒV2å¤±è´¥ï¼Œä½¿ç”¨V1ç»“æœ
            merged_result = {
                "status": "v1_fallback", 
                "analysis_result": v1_result.result,
                "v2_error": v2_result.error,
                "processing_info": {
                    "v1_processing_time": v1_result.processing_time,
                    "v2_error": v2_result.error,
                    "enhancement_applied": False,
                    "fallback_reason": "V2å¤„ç†å¤±è´¥"
                }
            }
            final_status = "v1_fallback"
            
        elif not v1_result.success and v2_result.success:
            # V1å¤±è´¥ï¼ŒV2æˆåŠŸï¼Œä½¿ç”¨V2ç»“æœ
            merged_result = {
                "status": "v2_only",
                "analysis_result": v2_result.result,
                "v1_error": v1_result.error,
                "processing_info": {
                    "v1_error": v1_result.error,
                    "v2_processing_time": v2_result.processing_time,
                    "enhancement_applied": True,
                    "fallback_reason": "V1å¤„ç†å¤±è´¥"
                }
            }
            final_status = "success"
            
        else:
            # ä¸¤ä¸ªéƒ½å¤±è´¥
            merged_result = {
                "status": "failure",
                "v1_error": v1_result.error,
                "v2_error": v2_result.error,
                "processing_info": {
                    "v1_error": v1_result.error,
                    "v2_error": v2_result.error,
                    "enhancement_applied": False,
                    "fallback_reason": "æ‰€æœ‰å¤„ç†ç®¡é“éƒ½å¤±è´¥"
                }
            }
            final_status = "failure"
        
        return merged_result, final_status
    
    def _generate_comparison_analysis(self, v1_result: ProcessingResult, v2_result: ProcessingResult) -> Dict[str, Any]:
        """ç”ŸæˆV1 vs V2å¯¹æ¯”åˆ†æ"""
        
        comparison = {
            "processing_comparison": {
                "v1_success": v1_result.success,
                "v2_success": v2_result.success,
                "v1_processing_time": v1_result.processing_time,
                "v2_processing_time": v2_result.processing_time,
                "time_difference": abs(v1_result.processing_time - v2_result.processing_time),
                "faster_version": "v1" if v1_result.processing_time < v2_result.processing_time else "v2"
            },
            "quality_comparison": {},
            "feature_comparison": {
                "v1_features": ["åŸºç¡€æ–‡æœ¬åˆ†æ", "æƒ…æ„Ÿåˆ†ç±»", "å…³é”®è¯æå–"],
                "v2_features": ["å¤šAgentåˆ†æ", "ç»“æ„åŒ–æ•°æ®å¤„ç†", "NPSæ·±åº¦åˆ†æ", "è´¨é‡è¯„ä¼°"]
            }
        }
        
        # å¦‚æœä¸¤ä¸ªéƒ½æˆåŠŸï¼Œè¿›è¡Œæ›´è¯¦ç»†çš„å¯¹æ¯”
        if v1_result.success and v2_result.success:
            try:
                v1_data = v1_result.result
                v2_data = v2_result.result
                
                # æ¯”è¾ƒåˆ†æç»“æœçš„å¤æ‚åº¦å’Œæ·±åº¦
                v1_text_length = len(str(v1_data)) if v1_data else 0
                v2_text_length = len(str(v2_data)) if v2_data else 0
                
                comparison["quality_comparison"] = {
                    "result_complexity": {
                        "v1_result_size": v1_text_length,
                        "v2_result_size": v2_text_length,
                        "complexity_ratio": v2_text_length / v1_text_length if v1_text_length > 0 else 0
                    },
                    "analysis_depth": {
                        "v1_analysis_type": "åŸºç¡€åˆ†æ",
                        "v2_analysis_type": "å¢å¼ºåˆ†æ",
                        "enhancement_value": "æä¾›æ›´æ·±å…¥çš„NPSæ´å¯Ÿå’Œç»“æ„åŒ–æ•°æ®"
                    }
                }
                
            except Exception as e:
                comparison["quality_comparison"]["error"] = f"å¯¹æ¯”åˆ†æç”Ÿæˆå¤±è´¥: {e}"
        
        return comparison
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "v2_enabled": self.enable_v2,
            "v2_timeout": self.v2_timeout,
            "processor_status": "active",
            "supported_features": {
                "parallel_processing": True,
                "automatic_fallback": True,
                "result_comparison": True,
                "data_recording": True
            }
        }

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    processor = ParallelProcessor(enable_v2=True, v2_timeout=60.0)
    
    # ç¤ºä¾‹è¾“å…¥æ•°æ®
    sample_input = {
        "survey_response_data": {
            "survey_metadata": {
                "survey_type": "product_nps",
                "survey_title": "æµ‹è¯•è°ƒç ”"
            },
            "response_data": [
                {
                    "response_metadata": {"user_id": "1", "response_id": "test1"},
                    "nps_score": {"value": 8, "category": "passive"},
                    "open_responses": {
                        "specific_reasons": {
                            "positive": "äº§å“è´¨é‡ä¸é”™",
                            "negative": ""
                        }
                    }
                }
            ]
        }
    }
    
    # æ‰§è¡Œå¹¶è¡Œå¤„ç†
    result = await processor.process_parallel(sample_input)
    
    print(f"å¤„ç†çŠ¶æ€: {result.final_status}")
    print(f"æ€»è€—æ—¶: {result.total_processing_time:.2f}ç§’")
    print(f"V1æˆåŠŸ: {result.v1_result.success}")
    print(f"V2æˆåŠŸ: {result.v2_result.success}")

if __name__ == "__main__":
    asyncio.run(main())